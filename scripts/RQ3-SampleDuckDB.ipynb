{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "SCRIPDIR = os.path.dirname(os.path.abspath(\"test.ipynb\"))\n",
    "sys.path.append(os.path.dirname(SCRIPDIR))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils import SETUP_PATH, convert_testfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_results = pd.read_csv('output/duckdb_duckdb_results.csv')\n",
    "results = original_results.copy() \n",
    "# change the TESTFILE_PATH in results\n",
    "results['TESTFILE_NAME'] = results['TESTFILE_PATH'].apply(lambda x: convert_testfile_name(x, 'duckdb'))    \n",
    "\n",
    "path = SETUP_PATH['filter']\n",
    "filter_df = pd.concat([pd.read_csv(f\"{path}/{file}\") for file in os.listdir(\n",
    "    path) if file.endswith('.csv')], ignore_index=True)\n",
    "filter_df[['TESTCASE_INDEX', 'CLUSTER']] = filter_df[[\n",
    "    'TESTCASE_INDEX', 'CLUSTER']].astype(int)\n",
    "\n",
    "# results_filtered = results[results['TESTFILE_NAME'].isin(filter_df['TESTFILE_NAME'])]\n",
    "results_filtered = results.merge(filter_df, on='TESTFILE_NAME', how='inner')\n",
    "# results_filtered = results_filtered[results_filtered\n",
    "filtered = results_filtered[(results_filtered['TESTCASE_INDEX_x'] == results_filtered['TESTCASE_INDEX_y']) | (results_filtered['TESTCASE_INDEX_y'] == -1)].drop(columns=['TESTCASE_INDEX_y', 'CLUSTER', 'TESTFILE_NAME']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_30 = errors.sample(n=30)\n",
    "errors = original_results[original_results['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "sample_100['ERROR_REASON'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre labeling\n",
    "import re\n",
    "sample_100.loc[sample_100.apply(lambda x: x['ERROR_MSG'].find('__TEST_DIR__') != -1, axis=1), 'ERROR_REASON'] = 1\n",
    "sample_100.loc[sample_100.apply(lambda x: str(x['ACTUAL_RESULT']).find(\"{'key'}\") != -1, axis=1), 'ERROR_REASON'] = 2\n",
    "sample_100.loc[sample_100.apply(lambda x: re.search(r\"\\{.*\\}\", str(x['ACTUAL_RESULT']), re.DOTALL) is not None and re.search(r\"\\{.*\\}\", str(x['EXPECTED_RESULT']), re.DOTALL) is not None, axis=1), 'ERROR_REASON'] = 2\n",
    "sample_100.loc[sample_100.apply(lambda x: re.search(r\"\\[.*\\]\", str(x['ACTUAL_RESULT']), re.DOTALL) is not None and re.search(r\"\\[].*\\]\", str(x['EXPECTED_RESULT']), re.DOTALL) is not None, axis=1), 'ERROR_REASON'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"output/duckdb_sample_100.csv\"\n",
    "output_reason_path = \"output/duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = results[results['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the sample\n",
    "print(sample.TESTFILE_PATH)\n",
    "\n",
    "# open the file and see if there's a pattern inside\n",
    "with open(sample.TESTFILE_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"con1\" in line:\n",
    "            print(line)\n",
    "            break\n",
    "    else:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[['SQL','ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT','EXPECTED_RESULT',  ]]\n",
    "reasons_mapping = pd.read_csv('data/error_reason_manual.csv')\n",
    "\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping, right_on='index',left_on = 'ERROR_REASON', how='inner')\n",
    "visible_reasons.drop(columns=['index'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llr}\n",
      " &  & DESCRIPTION \\\\\n",
      "SUPER_TAG & TAG &  \\\\\n",
      "\\multirow[c]{2}{*}{Client} & Data Type & 66 \\\\\n",
      " & Numeric & 9 \\\\\n",
      "Environment & File Paths & 20 \\\\\n",
      "\\multirow[c]{2}{*}{Misc} & Function & 1 \\\\\n",
      " & Parser & 4 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG', 'TAG', 'DESCRIPTION']].groupby(['SUPER_TAG', 'TAG']).count().style.to_latex()\n",
    "print(reason_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
