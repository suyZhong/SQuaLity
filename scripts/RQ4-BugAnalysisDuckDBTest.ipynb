{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "SCRIPDIR = os.path.dirname(os.path.abspath(\"test.ipynb\"))\n",
    "sys.path.append(os.path.dirname(SCRIPDIR))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_a_sample(check_df: pd.DataFrame, result_df: pd.DataFrame = None, idx:int = None):\n",
    "    if check_df[check_df['ERROR_REASON'].isna()].shape[0] == 0:\n",
    "        print(\"No error found!\")\n",
    "        return None\n",
    "    if idx is not None:\n",
    "        sample = check_df.loc[[idx]]\n",
    "    else:\n",
    "        sample = check_df[check_df['ERROR_REASON'].isna() & check_df['IS_ERROR'] == True].sample()\n",
    "    # if result_log is not None:\n",
    "    print(\"-----------I have the schema generated as follows:---------\")\n",
    "        # logs = result_log.iloc[sample.LOGS_INDEX.values[0]]\n",
    "    temp_df = result_df[result_df['TESTFILE_PATH'] == sample['TESTFILE_PATH'].values[0]]\n",
    "    print(sample.index)\n",
    "    for sql in temp_df[(temp_df['CASE_TYPE'] == 'Statement') | (temp_df.index == sample.index.values[0])]['SQL']:\n",
    "        print(sql + ';')\n",
    "        # print(logs.values[0])\n",
    "    print(\"-----------The SQL commands is:---------\")\n",
    "    print(sample.SQL.values[0])\n",
    "    print(\"-----------The expected result is:---------\")\n",
    "    print(sample.EXPECTED_RESULT.values[0])\n",
    "    print(\"-----------The actual result is:---------\")\n",
    "    print(sample.ACTUAL_RESULT.values[0])\n",
    "    print(\"-----------The error message is:---------\")\n",
    "    print(sample.ERROR_MSG.values[0])\n",
    "\n",
    "    print(\"-----------The test file is:---------\")\n",
    "    print(sample.TESTFILE_PATH.values[0])\n",
    "    print(\"___________The index is:___________\")\n",
    "    print(sample.index.values[0])\n",
    "    return sample.index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'sqlite'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5094147335727458\n",
      "Queries: 7384, Statements: 2725\n",
      "Wrong Queries: 569\n"
     ]
    }
   ],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_results.csv\")\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------I have the schema generated as follows:---------\n",
      "Int64Index([1746], dtype='int64')\n",
      "PRAGMA enable_verification;\n",
      "SELECT c0 FROM generate_series(NULL, NULL, NULL) t3(c0);;\n",
      "-----------The SQL commands is:---------\n",
      "SELECT c0 FROM generate_series(NULL, NULL, NULL) t3(c0);\n",
      "-----------The expected result is:---------\n",
      "nan\n",
      "-----------The actual result is:---------\n",
      "False\n",
      "-----------The error message is:---------\n",
      "near \"(\": syntax error\n",
      "-----------The test file is:---------\n",
      "duckdb_tests/fuzzer/afl/generate_series_null.test\n",
      "___________The index is:___________\n",
      "1746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1746"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE_CAST\n",
      "unrecognized token: \":\"\n",
      "1371\n",
      "RANGE\n",
      "Range not supported\n",
      "549\n",
      "GENERAL\n",
      "no such function: \n",
      "1516\n",
      "EXPLAIN\n",
      "query plan difference\n",
      "240\n",
      "SYNTAX\n",
      "syntax error\n",
      "3584\n",
      "Tag NESTDATA is not in the test filter, implement it first!\n",
      "Tag REPLACE is not in the test filter, implement it first!\n",
      "Tag SET is not in the test filter, implement it first!\n",
      "Tag REFERENCE is not in the test filter, implement it first!\n",
      "Tag ALTERALTER is not in the test filter, implement it first!\n",
      "Tag SQL is not in the test filter, implement it first!\n",
      "Tag OP is not in the test filter, implement it first!\n",
      "Tag ALIAS is not in the test filter, implement it first!\n",
      "Result MisMatch:  496\n"
     ]
    }
   ],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'TYPE_CAST': lambda x: re.match(r'unrecognized token: \\\":\\\"', str(x['ERROR_MSG'])) is not None,\n",
    "    'RANGE': lambda x: re.search(r'range\\((.*?)\\)', str(x['SQL']), re.DOTALL | re.IGNORECASE) is not None,\n",
    "    \"GENERAL\": lambda x: re.search(r'no such function: .*', str(x['ERROR_MSG']), re.IGNORECASE) is not None,\n",
    "    \"EXPLAIN\": lambda x: re.match(r'EXPLAIN', str(x['SQL'])) is not None,\n",
    "    \"SYNTAX\": lambda x: re.search(r'syntax error', str(x['ERROR_MSG']), re.IGNORECASE) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------I have the schema generated as follows:---------\n",
      "SET default_null_order='nulls_first';\n",
      "PRAGMA enable_verification;\n",
      "create table students (course VARCHAR, type VARCHAR);\n",
      "insert into students \t\t(course, type) \tvalues \t\t('CS', 'Bachelor'), \t\t('CS', 'Bachelor'), \t\t('CS', 'PhD'), \t\t('Math', 'Masters'), \t\t('CS', NULL), \t\t('CS', NULL), \t\t('Math', NULL);\n",
      "select course from students group by ();\n",
      "-----------The SQL commands is:---------\n",
      "select count(*), course, type\n",
      "        from students\n",
      "        group by grouping sets((2, 3), (3))\n",
      "        order by 1, 2, 3;\n",
      "-----------The expected result is:---------\n",
      "1\tNULL\tMasters\n",
      "1\tNULL\tPhD\n",
      "1\tCS\tPhD\n",
      "1\tMath\tNULL\n",
      "1\tMath\tMasters\n",
      "2\tNULL\tBachelor\n",
      "2\tCS\tNULL\n",
      "2\tCS\tBachelor\n",
      "3\tNULL\tNULL\n",
      "-----------The actual result is:---------\n",
      "False\n",
      "-----------The error message is:---------\n",
      "near \"sets\": syntax error\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duckdb_tests/sql/transactions/test_transaction_local_unique_ops.test\n"
     ]
    }
   ],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/duckdb_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Command & 20 \\\\\n",
      "Func Syntax & 64 \\\\\n",
      "Operation & 15 \\\\\n",
      "Setting & 1 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPER_TAG    DESCRIPTION                                                                                           \n",
      "Func Syntax  Specific built-in function not supported                                                                  26\n",
      "             Nested data type unsupported ({'x': 1})                                                                   13\n",
      "             Type cast in DuckDB is '::', which is unsupported in SQLite                                               13\n",
      "Operation    CTE ALIAS not permitted                                                                                   10\n",
      "Command      SQLite does not support alter column/name directly using ALTER TABLE                                       6\n",
      "Func Syntax  Function range() not supported                                                                             6\n",
      "Command      CREATE things not supported (SCHEMA, MACRO, TYPE)                                                          5\n",
      "             No Set in SQLite                                                                                           4\n",
      "Func Syntax  Datetime type not supported                                                                                3\n",
      "Operation    SQLite would cast to text if meet unknow type in CAST()                                                    2\n",
      "Func Syntax  Type Union not supported                                                                                   2\n",
      "Operation    SQLite not support create a view using cte\\n                                                               1\n",
      "             Original test suite not allowed time but sqlite allowed                                                    1\n",
      "             ASOF_JOIN not supported                                                                                    1\n",
      "Command      ANY operator not supported                                                                                 1\n",
      "Func Syntax  REGEX select not supported                                                                                 1\n",
      "Command      SQLite does not natively support the GROUPING SETS, CUBE, or ROLLUP extensions to the GROUP BY clause.     1\n",
      "             SHOW not supported                                                                                         1\n",
      "             Not supported SQL UNPIVOT\\n                                                                                1\n",
      "             No CREATE OR REPLACE                                                                                       1\n",
      "Setting      Unknown system variable                                                                                    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "des_cnt = visible_reasons.value_counts(['SUPER_TAG','DESCRIPTION'])\n",
    "print(des_cnt)\n",
    "des_cnt.to_csv('output/demo_sltddb_cnt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'postgresql'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_results.csv\")\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/duckdb_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'mysql'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_results.csv\")\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') &\n",
    "                   (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement') &\n",
    "                      (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (\n",
    "    df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'TYPE_CAST': lambda x: re.match(r'1064 \\(42000\\).*\\'::', str(x['ERROR_MSG'])) is not None,\n",
    "    'GENERAL': lambda x: re.match(r'1305 \\(42000\\)', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/duckdb_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
