{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "SCRIPDIR = os.path.dirname(os.path.abspath(\"test.ipynb\"))\n",
    "sys.path.append(os.path.dirname(SCRIPDIR))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_a_sample(check_df: pd.DataFrame, result_df: pd.DataFrame = None, idx:int = None):\n",
    "    if check_df[check_df['ERROR_REASON'].isna()].shape[0] == 0:\n",
    "        print(\"No error found!\")\n",
    "        return None\n",
    "    if idx is not None:\n",
    "        sample = check_df.loc[[idx]]\n",
    "    else:\n",
    "        sample = check_df[check_df['ERROR_REASON'].isna() & check_df['IS_ERROR'] == True].sample()\n",
    "    # if result_log is not None:\n",
    "    print(\"-----------I have the schema generated as follows:---------\")\n",
    "        # logs = result_log.iloc[sample.LOGS_INDEX.values[0]]\n",
    "    temp_df = result_df[result_df['TESTFILE_PATH'] == sample['TESTFILE_PATH'].values[0]]\n",
    "    print(sample.index)\n",
    "    for sql in temp_df[(temp_df['CASE_TYPE'] == 'Statement') | (temp_df.index == sample.index.values[0])]['SQL']:\n",
    "        print(sql + ';')\n",
    "        # print(logs.values[0])\n",
    "    print(\"-----------The SQL commands is:---------\")\n",
    "    print(sample.SQL.values[0])\n",
    "    print(\"-----------The expected result is:---------\")\n",
    "    print(sample.EXPECTED_RESULT.values[0])\n",
    "    print(\"-----------The actual result is:---------\")\n",
    "    print(sample.ACTUAL_RESULT.values[0])\n",
    "    print(\"-----------The error message is:---------\")\n",
    "    print(sample.ERROR_MSG.values[0])\n",
    "\n",
    "    print(\"-----------The test file is:---------\")\n",
    "    print(sample.TESTFILE_PATH.values[0])\n",
    "    print(\"___________The index is:___________\")\n",
    "    print(sample.index.values[0])\n",
    "    return sample.index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'sqlite'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5145124033343377\n",
      "Queries: 7104, Statements: 2564\n",
      "Wrong Queries: 625\n"
     ]
    }
   ],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_results.csv\")\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'TYPE_CAST': lambda x: re.match(r'unrecognized token: \\\":\\\"', str(x['ERROR_MSG'])) is not None,\n",
    "    'NESTF': lambda x: re.search(r'range\\((.*?)\\)', str(x['SQL']), re.DOTALL | re.IGNORECASE) is not None,\n",
    "    \"GENERAL\": lambda x: re.search(r'no such function: .*', str(x['ERROR_MSG']), re.IGNORECASE) is not None,\n",
    "    \"EXPLAIN\": lambda x: re.match(r'EXPLAIN', str(x['SQL'])) is not None,\n",
    "    # \"SYNTAX\": lambda x: re.search(r'syntax error', str(x['ERROR_MSG']), re.IGNORECASE) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(sample['TESTFILE_PATH'])\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/duckdb_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Clause & 14 \\\\\n",
      "Command & 23 \\\\\n",
      "Function & 2 \\\\\n",
      "Operator & 14 \\\\\n",
      "Type & 13 \\\\\n",
      "UFunction & 34 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_cnt = visible_reasons.value_counts(['SUPER_TAG','DESCRIPTION'])\n",
    "print(des_cnt)\n",
    "des_cnt.to_csv('output/demo_sltddb_cnt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'postgresql'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_results.csv\")\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/duckdb_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Clause & 9 \\\\\n",
      "Command & 16 \\\\\n",
      "Function & 6 \\\\\n",
      "IType & 3 \\\\\n",
      "Misc & 1 \\\\\n",
      "Setting & 3 \\\\\n",
      "Type & 36 \\\\\n",
      "UFunction & 26 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'mysql'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_results.csv\")\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_duckdb_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') &\n",
    "                   (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement') &\n",
    "                      (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (\n",
    "    df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'TYPE_CAST': lambda x: re.match(r'1064 \\(42000\\).*\\'::', str(x['ERROR_MSG'])) is not None,\n",
    "    # 'GENERAL': lambda x: re.match(r'1305 \\(42000\\)', str(x['ERROR_MSG'])) is not None,\n",
    "    'PRAGMA': lambda x: re.match(r'1064 \\(42000\\).*\\'PRAGMA', str(x['ERROR_MSG']), re.IGNORECASE) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "output_path = f\"output/{dbms_name}_duckdb_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_duckdb_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for sql in temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']:\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/duckdb_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Clause & 21 \\\\\n",
      "Command & 20 \\\\\n",
      "ICommand & 1 \\\\\n",
      "IOperator & 1 \\\\\n",
      "Misc & 3 \\\\\n",
      "Operator & 10 \\\\\n",
      "Setting & 4 \\\\\n",
      "Type & 22 \\\\\n",
      "UFunction & 18 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visible_reasons = pd.read_csv(output_reason_path)\n",
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause       18\n",
      "Command      12\n",
      "UFunction     9\n",
      "Type          5\n",
      "Misc          4\n",
      "Operator      3\n",
      "Function      3\n",
      "IType         2\n",
      "Setting       1\n",
      "IOperator     1\n",
      "ICommand      1\n",
      "Name: SUPER_TAG, dtype: int64\n",
      "SUPER_TAG\n",
      "Clause       18\n",
      "Command      12\n",
      "UFunction     9\n",
      "Type          5\n",
      "Misc          4\n",
      "Function      3\n",
      "Operator      3\n",
      "IType         2\n",
      "ICommand      1\n",
      "IOperator     1\n",
      "Setting       1\n",
      "dtype: int64\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  ERROR\\_REASON &  ERROR\\_REASON &  ERROR\\_REASON \\\\\n",
      "SUPER\\_TAG &               &               &               \\\\\n",
      "\\midrule\n",
      "Clause    &            14 &             9 &            21 \\\\\n",
      "Command   &            23 &            16 &            20 \\\\\n",
      "Function  &             2 &             6 &             0 \\\\\n",
      "ICommand  &             0 &             0 &             1 \\\\\n",
      "IOperator &             0 &             0 &             1 \\\\\n",
      "IType     &             0 &             3 &             0 \\\\\n",
      "Misc      &             0 &             1 &             3 \\\\\n",
      "Operator  &            14 &             0 &            10 \\\\\n",
      "Setting   &             0 &             3 &             4 \\\\\n",
      "Type      &            13 &            36 &            22 \\\\\n",
      "UFunction &            34 &            26 &            18 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1441782/4090415852.py:47: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(join_df.to_latex())\n"
     ]
    }
   ],
   "source": [
    "reasons = pd.read_csv(\"data/duckdb_suite_errors.csv\")\n",
    "\n",
    "sqlite_results = pd.read_csv(\"output/sqlite_duckdb_sample_100_reason.csv\")\n",
    "reason_df = sqlite_results[['SQL', 'EXPECTED_RESULT',\n",
    "                            'ACTUAL_RESULT', 'ERROR_REASON']]\n",
    "sqlite_reasons = reason_df['ERROR_REASON'].value_counts()\n",
    "\n",
    "\n",
    "postgresql_results = pd.read_csv(\"output/postgresql_duckdb_sample_100_reason.csv\")\n",
    "reason_df = postgresql_results[['SQL', 'EXPECTED_RESULT',\n",
    "                                'ACTUAL_RESULT', 'ERROR_REASON']]\n",
    "postgresql_reasons = reason_df['ERROR_REASON'].value_counts()\n",
    "\n",
    "# mysql\n",
    "mysql_results = pd.read_csv(\"output/mysql_duckdb_sample_100_reason.csv\")\n",
    "reason_df = mysql_results[['SQL', 'EXPECTED_RESULT',\n",
    "                           'ACTUAL_RESULT', 'ERROR_REASON']]\n",
    "mysql_reasons = reason_df['ERROR_REASON'].value_counts()\n",
    "\n",
    "# print(sqlite_reasons)\n",
    "# print(postgresql_reasons)\n",
    "# outer join two dataframes\n",
    "\n",
    "join_df = pd.concat([sqlite_reasons, postgresql_reasons,\n",
    "                    mysql_reasons], axis=1, join='outer')\n",
    "# print(join_df)\n",
    "\n",
    "join_df.fillna(0, inplace=True)\n",
    "join_df = join_df.astype(int)\n",
    "\n",
    "# pure_reasons = reasons[['TAG', 'REASON']].drop_duplicates()\n",
    "pure_reasons = reasons[['TAG', 'SUPER_TAG']].drop_duplicates()\n",
    "print(pure_reasons['SUPER_TAG'].value_counts())\n",
    "# join the join_df and the reasons dataframe, drop duplicate rows\n",
    "join_df = join_df.join(pure_reasons.set_index('TAG'),  how='left')\n",
    "join_df.sort_values(by=['SUPER_TAG'], inplace=True)\n",
    "detail_df = join_df.copy()\n",
    "\n",
    "detail_df.drop(columns=['ERROR_REASON'], inplace=True)\n",
    "print(detail_df.value_counts())\n",
    "# sum the rows with the same SUPER_TAG\n",
    "join_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# unique_reasons = join_df['SUPER_TAG'].drop_duplicates()\n",
    "join_df = join_df.groupby('SUPER_TAG').sum()\n",
    "\n",
    "print(join_df.to_latex())\n",
    "# join_df.style.to_latex(\"output/error_reasons.tex\", )\n",
    "\n",
    "# unique_reasons = join_df['SUPER_TAG'].drop_duplicates()\n",
    "# print(unique_reasons)\n",
    "\n",
    "output_df = detail_df.value_counts()\n",
    "\n",
    "schema = \"\\\\newcommand{\\\\DuckDBCompatibilityIssue%s}{%s}\\n\"\n",
    "with open(\"output/Variables.tex\", \"a\") as f:\n",
    "    \n",
    "    f.write(schema % ('SQL', output_df['Clause'] + output_df['Command']))\n",
    "    f.write(schema % ('Function', output_df['UFunction'] ))\n",
    "    f.write(schema % ('Type', output_df['Type']))\n",
    "    f.write(schema % ('Operator', output_df['Operator']))\n",
    "    f.write(schema % ('Configuration', output_df['Setting']))\n",
    "    f.write(schema % ('Semantic', output_df['Function'] + output_df['IOperator'] + output_df['ICommand'] + output_df['IType']))\n",
    "    f.write(schema % ('Misc', output_df['Misc']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
