{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "SCRIPDIR = os.path.dirname(os.path.abspath(\"test.ipynb\"))\n",
    "sys.path.append(os.path.dirname(SCRIPDIR))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_a_sample(check_df: pd.DataFrame, result_df: pd.DataFrame = None, idx:int = None):\n",
    "    if check_df[check_df['ERROR_REASON'].isna()].shape[0] == 0:\n",
    "        print(\"No error found!\")\n",
    "        return None\n",
    "    if idx is not None:\n",
    "        sample = check_df.loc[[idx]]\n",
    "    else:\n",
    "        sample = check_df[check_df['ERROR_REASON'].isna() & check_df['IS_ERROR'] == True].sample()\n",
    "    # if result_log is not None:\n",
    "    print(\"-----------I have the schema generated as follows:---------\")\n",
    "        # logs = result_log.iloc[sample.LOGS_INDEX.values[0]]\n",
    "    temp_df = result_df[result_df['TESTFILE_PATH'] == sample['TESTFILE_PATH'].values[0]]\n",
    "    print(sample.index)\n",
    "    for idx, sql in enumerate(temp_df[(temp_df['CASE_TYPE'] == 'Statement') | (temp_df.index == sample.index.values[0])]['SQL']):\n",
    "        if idx >= 100:\n",
    "            break\n",
    "        print(sql + ';')\n",
    "        # print(logs.values[0])\n",
    "    print(\"-----------The SQL commands is:---------\")\n",
    "    print(sample.SQL.values[0])\n",
    "    print(\"-----------The expected result is:---------\")\n",
    "    print(sample.EXPECTED_RESULT.values[0])\n",
    "    print(\"-----------The actual result is:---------\")\n",
    "    print(sample.ACTUAL_RESULT.values[0])\n",
    "    print(\"-----------The error message is:---------\")\n",
    "    print(sample.ERROR_MSG.values[0])\n",
    "\n",
    "    print(\"-----------The test file is:---------\")\n",
    "    print(sample.TESTFILE_PATH.values[0])\n",
    "    print(\"___________The index is:___________\")\n",
    "    print(sample.index.values[0])\n",
    "    return sample.index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'sqlite'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_results.csv\")\n",
    "df = df[df['SQL'].isnull() == False]\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'SET': lambda x: re.match(r'SET', str(x['SQL'])) is not None and re.search(r'syntax error', str(x['ERROR_MSG'])) is not None,\n",
    "    'PSQL_CMD': lambda x: re.match(r'\\\\', str(x['SQL'])) is not None and re.search(r'unrecognized token', str(x['ERROR_MSG'])) is not None,\n",
    "    'TYPE_CAST': lambda x: re.match(r'unrecognized token: \\\":\\\"', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for idx, sql in enumerate(temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']):\n",
    "    if idx >= 10:\n",
    "        break\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/postgresql_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'mysql'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_results.csv\")\n",
    "df = df[df['SQL'].isnull() == False]\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'TYPE_CAST': lambda x: re.match(r'1064 \\(42000\\).*\\'::', str(x['ERROR_MSG'])) is not None,\n",
    "    'GENERAL': lambda x: re.match(r'1305 \\(42000\\)', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for idx, sql in enumerate(temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']):\n",
    "    if idx >= 100:\n",
    "        break\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/postgresql_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'duckdb'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28624733475479747\n",
      "Queries: 9527, Statements: 10558\n",
      "Wrong Queries: 1150\n"
     ]
    }
   ],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_results.csv\")\n",
    "df = df[df['SQL'].isnull() == False]\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------I have the schema generated as follows:---------\n",
      "Int64Index([22372], dtype='int64')\n",
      "create domain domaindroptest int4;\n",
      "comment on domain domaindroptest is 'About to drop this..';\n",
      "create domain dependenttypetest domaindroptest;\n",
      "drop domain domaindroptest;\n",
      "drop domain domaindroptest cascade;\n",
      "create domain domainvarchar varchar(5);\n",
      "create domain domainnumeric numeric(8,2);\n",
      "create domain domainint4 int4;\n",
      "create domain domaintext text;\n",
      "create table basictest\n",
      "           ( testint4 domainint4\n",
      "           , testtext domaintext\n",
      "           , testvarchar domainvarchar\n",
      "           , testnumeric domainnumeric\n",
      "           );\n",
      "INSERT INTO basictest values ('88', 'haha', 'short', '123.12');      ;\n",
      "INSERT INTO basictest values ('88', 'haha', 'short text', '123.12');\n",
      "INSERT INTO basictest values ('88', 'haha', 'short', '123.1212');    ;\n",
      "COPY basictest (testvarchar) FROM stdin;\n",
      "COPY basictest (testvarchar) FROM stdin;\n",
      "drop table basictest;\n",
      "drop domain domainvarchar restrict;\n",
      "drop domain domainnumeric restrict;\n",
      "drop domain domainint4 restrict;\n",
      "drop domain domaintext;\n",
      "create domain domainint4arr int4[1];\n",
      "create domain domainchar4arr varchar(4)[2][3];\n",
      "create table domarrtest\n",
      "           ( testint4arr domainint4arr\n",
      "           , testchar4arr domainchar4arr\n",
      "            );\n",
      "INSERT INTO domarrtest values ('{2,2}', '{{\"a\",\"b\"},{\"c\",\"d\"}}');\n",
      "INSERT INTO domarrtest values ('{{2,2},{2,2}}', '{{\"a\",\"b\"}}');\n",
      "INSERT INTO domarrtest values ('{2,2}', '{{\"a\",\"b\"},{\"c\",\"d\"},{\"e\",\"f\"}}');\n",
      "INSERT INTO domarrtest values ('{2,2}', '{{\"a\"},{\"c\"}}');\n",
      "INSERT INTO domarrtest values (NULL, '{{\"a\",\"b\",\"c\"},{\"d\",\"e\",\"f\"}}');\n",
      "INSERT INTO domarrtest values (NULL, '{{\"toolong\",\"b\",\"c\"},{\"d\",\"e\",\"f\"}}');\n",
      "INSERT INTO domarrtest (testint4arr[1], testint4arr[3]) values (11,22);\n",
      "COPY domarrtest FROM stdin;\n",
      "COPY domarrtest FROM stdin;\t;\n",
      "update domarrtest set\n",
      "  testint4arr[1] = testint4arr[1] + 1,\n",
      "  testint4arr[3] = testint4arr[3] - 1\n",
      "where testchar4arr is null;\n",
      "drop table domarrtest;\n",
      "drop domain domainint4arr restrict;\n",
      "drop domain domainchar4arr restrict;\n",
      "create domain dia as int[];\n",
      "select array_dims('{1,2,3}'::dia);\n",
      "drop domain dia;\n",
      "create type comptype as (r float8, i float8);\n",
      "create domain dcomptype as comptype;\n",
      "create table dcomptable (d1 dcomptype unique);\n",
      "insert into dcomptable values (row(1,2)::dcomptype);\n",
      "insert into dcomptable values (row(3,4)::comptype);\n",
      "insert into dcomptable values (row(1,2)::dcomptype);\n",
      "insert into dcomptable (d1.r) values(11);\n",
      "update dcomptable set d1.r = (d1).r + 1 where (d1).i > 0;\n",
      "alter domain dcomptype add constraint c1 check ((value).r <= (value).i);\n",
      "alter domain dcomptype add constraint c2 check ((value).r > (value).i);\n",
      "select row(2,1)::dcomptype;\n",
      "insert into dcomptable values (row(1,2)::comptype);\n",
      "insert into dcomptable values (row(2,1)::comptype);\n",
      "insert into dcomptable (d1.r) values(99);\n",
      "insert into dcomptable (d1.r, d1.i) values(99, 100);\n",
      "insert into dcomptable (d1.r, d1.i) values(100, 99);\n",
      "update dcomptable set d1.r = (d1).r + 1 where (d1).i > 0;\n",
      "update dcomptable set d1.r = (d1).r - 1, d1.i = (d1).i + 1 where (d1).i > 0;\n",
      "create rule silly as on delete to dcomptable do instead\n",
      "  update dcomptable set d1.r = (d1).r - 1, d1.i = (d1).i + 1 where (d1).i > 0;\n",
      "create function makedcomp(r float8, i float8) returns dcomptype\n",
      "as 'select row(r, i)' language sql;\n",
      "select makedcomp(2,1);\n",
      "drop function makedcomp(float8, float8);\n",
      "drop table dcomptable;\n",
      "create type comptype as (r float8, i float8);\n",
      "create domain dcomptype as comptype;\n",
      "alter domain dcomptype add constraint c1 check ((value).r > 0);\n",
      "comment on constraint c1 on domain dcomptype is 'random commentary';\n",
      "select row(0,1)::dcomptype;\n",
      "alter type comptype alter attribute r type varchar;\n",
      "alter type comptype alter attribute r type bigint;\n",
      "alter type comptype drop attribute r;\n",
      "alter type comptype drop attribute i;\n",
      "create type comptype as (r float8, i float8);\n",
      "create domain dcomptypea as comptype[];\n",
      "create table dcomptable (d1 dcomptypea unique);\n",
      "insert into dcomptable values (array[row(1,2)]::dcomptypea);\n",
      "insert into dcomptable values (array[row(3,4), row(5,6)]::comptype[]);\n",
      "insert into dcomptable values (array[row(7,8)::comptype, row(9,10)::comptype]);\n",
      "insert into dcomptable values (array[row(1,2)]::dcomptypea);\n",
      "insert into dcomptable (d1[1]) values(row(9,10));\n",
      "insert into dcomptable (d1[1].r) values(11);\n",
      "update dcomptable set d1[2] = row(d1[2].i, d1[2].r);\n",
      "update dcomptable set d1[1].r = d1[1].r + 1 where d1[1].i > 0;\n",
      "alter domain dcomptypea add constraint c1 check (value[1].r <= value[1].i);\n",
      "alter domain dcomptypea add constraint c2 check (value[1].r > value[1].i);\n",
      "select array[row(2,1)]::dcomptypea;\n",
      "insert into dcomptable values (array[row(1,2)]::comptype[]);\n",
      "insert into dcomptable values (array[row(2,1)]::comptype[]);\n",
      "insert into dcomptable (d1[1].r) values(99);\n",
      "insert into dcomptable (d1[1].r, d1[1].i) values(99, 100);\n",
      "insert into dcomptable (d1[1].r, d1[1].i) values(100, 99);\n",
      "update dcomptable set d1[1].r = d1[1].r + 1 where d1[1].i > 0;\n",
      "update dcomptable set d1[1].r = d1[1].r - 1, d1[1].i = d1[1].i + 1\n",
      "  where d1[1].i > 0;\n",
      "create rule silly as on delete to dcomptable do instead\n",
      "  update dcomptable set d1[1].r = d1[1].r - 1, d1[1].i = d1[1].i + 1\n",
      "    where d1[1].i > 0;\n",
      "drop table dcomptable;\n",
      "create domain posint as int check (value > 0);\n",
      "create table pitable (f1 posint[]);\n",
      "insert into pitable values(array[42]);\n",
      "insert into pitable values(array[-1]);\n",
      "insert into pitable values('{0}');\n",
      "update pitable set f1[1] = f1[1] + 1;\n",
      "-----------The SQL commands is:---------\n",
      "select array_dims('{1,2,3}'::dia)\n",
      "-----------The expected result is:---------\n",
      "[1:3]\n",
      "-----------The actual result is:---------\n",
      "False\n",
      "-----------The error message is:---------\n",
      "Catalog Error: Scalar Function with name array_dims does not exist!\n",
      "Did you mean \"array_has\"?\n",
      "LINE 1: select array_dims('{1,2,3}'::dia)\n",
      "               ^\n",
      "-----------The test file is:---------\n",
      "postgresql_tests/regress/sql/domain.sql\n",
      "___________The index is:___________\n",
      "22372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22372"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag GENERAL is not in the test filter, implement it first!\n",
      "PGUNIQUE\n",
      "Postgresql unique function\n",
      "520\n",
      "Tag SYSV is not in the test filter, implement it first!\n",
      "Tag SYNTAX is not in the test filter, implement it first!\n",
      "Tag TYPENE is not in the test filter, implement it first!\n",
      "Tag CR_FUNC is not in the test filter, implement it first!\n",
      "Tag NUMERIC is not in the test filter, implement it first!\n",
      "Tag INHERIT is not in the test filter, implement it first!\n",
      "Tag SQL is not in the test filter, implement it first!\n",
      "Tag UPDATE_RET is not in the test filter, implement it first!\n",
      "Tag NIMPL is not in the test filter, implement it first!\n",
      "Tag PARTITION is not in the test filter, implement it first!\n",
      "Tag PSQL_CMD is not in the test filter, implement it first!\n",
      "Tag SERIES is not in the test filter, implement it first!\n",
      "Tag UCAST is not in the test filter, implement it first!\n",
      "Tag GEN_SERIES is not in the test filter, implement it first!\n",
      "Tag OP is not in the test filter, implement it first!\n",
      "Tag BIT_POSITION is not in the test filter, implement it first!\n",
      "Tag MISC is not in the test filter, implement it first!\n",
      "Result MisMatch:  1150\n"
     ]
    }
   ],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'PGUNIQUE': lambda x: re.search(r'pg\\_.* does not exist', str(x['ERROR_MSG'])) is not None,\n",
    "    # 'GENERAL': lambda x: re.search(r'Table Function with name .* does not exist', str(x['ERROR_MSG'])) is not None,\n",
    "    # 'TYPENE': lambda x: re.search(r'Type with name .* does not exist', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------I have the schema generated as follows:---------\n",
      "SET client_min_messages TO 'warning';\n",
      "DROP ROLE IF EXISTS regress_priv_group1;\n",
      "DROP ROLE IF EXISTS regress_priv_group2;\n",
      "DROP ROLE IF EXISTS regress_priv_user1;\n",
      "DROP ROLE IF EXISTS regress_priv_user2;\n",
      "DROP ROLE IF EXISTS regress_priv_user3;\n",
      "DROP ROLE IF EXISTS regress_priv_user4;\n",
      "DROP ROLE IF EXISTS regress_priv_user5;\n",
      "DROP ROLE IF EXISTS regress_priv_user6;\n",
      "DROP ROLE IF EXISTS regress_priv_user7;\n",
      "RESET client_min_messages;\n",
      "CREATE USER regress_priv_user1;\n",
      "CREATE USER regress_priv_user2;\n",
      "CREATE USER regress_priv_user3;\n",
      "CREATE USER regress_priv_user4;\n",
      "-----------The SQL commands is:---------\n",
      "select has_column_privilege('pg_authid','nosuchcol','select')\n",
      "-----------The expected result is:---------\n",
      "ERROR:  column \"nosuchcol\" of relation \"pg_authid\" does not exist\n",
      "-----------The actual result is:---------\n",
      "True\n",
      "-----------The error message is:---------\n",
      "None\n",
      "857\n"
     ]
    }
   ],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for idx, sql in enumerate(temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']):\n",
    "    if idx >= 15:\n",
    "        break\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql_tests/regress/sql/privileges.sql\n"
     ]
    }
   ],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/postgresql_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
