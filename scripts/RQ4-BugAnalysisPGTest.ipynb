{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "SCRIPDIR = os.path.dirname(os.path.abspath(\"test.ipynb\"))\n",
    "sys.path.append(os.path.dirname(SCRIPDIR))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_a_sample(check_df: pd.DataFrame, result_df: pd.DataFrame = None, idx:int = None):\n",
    "    if check_df[check_df['ERROR_REASON'].isna()].shape[0] == 0:\n",
    "        print(\"No error found!\")\n",
    "        return None\n",
    "    if idx is not None:\n",
    "        sample = check_df.loc[[idx]]\n",
    "    else:\n",
    "        sample = check_df[check_df['ERROR_REASON'].isna() & check_df['IS_ERROR'] == True].sample()\n",
    "    # if result_log is not None:\n",
    "    print(\"-----------I have the schema generated as follows:---------\")\n",
    "        # logs = result_log.iloc[sample.LOGS_INDEX.values[0]]\n",
    "    temp_df = result_df[result_df['TESTFILE_PATH'] == sample['TESTFILE_PATH'].values[0]]\n",
    "    print(sample.index)\n",
    "    for idx, sql in enumerate(temp_df[(temp_df['CASE_TYPE'] == 'Statement') | (temp_df.index == sample.index.values[0])]['SQL']):\n",
    "        if idx >= 100:\n",
    "            break\n",
    "        print(sql + ';')\n",
    "        # print(logs.values[0])\n",
    "    print(\"-----------The SQL commands is:---------\")\n",
    "    print(sample.SQL.values[0])\n",
    "    print(\"-----------The expected result is:---------\")\n",
    "    print(sample.EXPECTED_RESULT.values[0])\n",
    "    print(\"-----------The actual result is:---------\")\n",
    "    print(sample.ACTUAL_RESULT.values[0])\n",
    "    print(\"-----------The error message is:---------\")\n",
    "    print(sample.ERROR_MSG.values[0])\n",
    "\n",
    "    print(\"-----------The test file is:---------\")\n",
    "    print(sample.TESTFILE_PATH.values[0])\n",
    "    print(\"___________The index is:___________\")\n",
    "    print(sample.index.values[0])\n",
    "    return sample.index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'sqlite'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_results.csv\")\n",
    "df = df[df['SQL'].isnull() == False]\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'SET': lambda x: re.match(r'SET', str(x['SQL'])) is not None and re.search(r'syntax error', str(x['ERROR_MSG'])) is not None,\n",
    "    'PSQL_CMD': lambda x: re.match(r'\\\\', str(x['SQL'])) is not None and re.search(r'unrecognized token', str(x['ERROR_MSG'])) is not None,\n",
    "    'TYPE_CAST': lambda x: re.match(r'unrecognized token: \\\":\\\"', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for idx, sql in enumerate(temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']):\n",
    "    if idx >= 10:\n",
    "        break\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/postgresql_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Clause & 20 \\\\\n",
      "Command & 34 \\\\\n",
      "Operator & 20 \\\\\n",
      "Type & 15 \\\\\n",
      "UFunction & 11 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'mysql'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_results.csv\")\n",
    "df = df[df['SQL'].isnull() == False]\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'TYPE_CAST': lambda x: re.match(r'1064 \\(42000\\).*\\'::', str(x['ERROR_MSG'])) is not None,\n",
    "    'GENERAL': lambda x: re.match(r'1305 \\(42000\\)', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for idx, sql in enumerate(temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']):\n",
    "    if idx >= 15:\n",
    "        break\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])\n",
    "os.system(\"code \" + sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/postgresql_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Clause & 22 \\\\\n",
      "Command & 36 \\\\\n",
      "Operator & 16 \\\\\n",
      "Setting & 2 \\\\\n",
      "Type & 16 \\\\\n",
      "UFunction & 8 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_name = 'duckdb'\n",
    "\n",
    "output_path = f\"output/{dbms_name}_postgresql_sample_100.csv\"\n",
    "output_reason_path = f\"output/{dbms_name}_postgresql_sample_100_reason.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file and read the content\n",
    "df = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_results.csv\")\n",
    "df = df[df['SQL'].isnull() == False]\n",
    "result_log = pd.read_csv(f\"output/{dbms_name}_postgresql_filter_logs.csv\")\n",
    "error_percentage = df[df['IS_ERROR'] == True].shape[0] / df.shape[0]\n",
    "print(1 - error_percentage)\n",
    "error_queries = df[(df['CASE_TYPE'] == 'Query') & (df['IS_ERROR'] == True)].shape[0]\n",
    "error_statements = df[(df['CASE_TYPE'] == 'Statement')& (df['IS_ERROR'] == True)].shape[0]\n",
    "wrong_queries = df[(df['CASE_TYPE'] == 'Query') & (df['ERROR_MSG'] == 'Result MisMatch')].shape[0]\n",
    "print(f\"Queries: {error_queries}, Statements: {error_statements}\")\n",
    "print(f\"Wrong Queries: {wrong_queries}\")\n",
    "\n",
    "# add empty column ERROR_REASON to df\n",
    "df['ERROR_REASON'] = None\n",
    "check_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_a_sample(check_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from copy import copy\n",
    "import re\n",
    "\n",
    "TEMP_FILTER = {\n",
    "    'PGUNIQUE': lambda x: re.search(r'pg\\_.* does not exist', str(x['ERROR_MSG'])) is not None,\n",
    "    # 'GENERAL': lambda x: re.search(r'Table Function with name .* does not exist', str(x['ERROR_MSG'])) is not None,\n",
    "    # 'TYPENE': lambda x: re.search(r'Type with name .* does not exist', str(x['ERROR_MSG'])) is not None,\n",
    "}\n",
    "\n",
    "new_df = copy(df)\n",
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "tags = reasons[reasons['DBMS'] == dbms_name]['TAG'].values.tolist()\n",
    "for tag in tags:\n",
    "    if tag not in TEMP_FILTER:\n",
    "        print(f\"Tag {tag} is not in the test filter, implement it first!\")\n",
    "        continue\n",
    "    new_df.loc[new_df.apply(TEMP_FILTER[tag], axis=1) & new_df['IS_ERROR'] == True, 'ERROR_REASON'] = tag\n",
    "    print(tag)\n",
    "    print(reasons[reasons['TAG']==tag]['DESCRIPTION'].values[0])\n",
    "    # print(new_df[new_df['ERROR_REASON']==tag].info())\n",
    "    print(new_df[new_df['ERROR_REASON']==tag].shape[0])\n",
    "\n",
    "check_df = copy(new_df[new_df['IS_ERROR'] == True & new_df['ERROR_REASON'].isna()])\n",
    "print(\"Result MisMatch: \", check_df[check_df['ERROR_MSG'] == 'Result MisMatch'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new_df[new_df['IS_ERROR'] == True]\n",
    "sample_100 = errors.sample(n=100, random_state=233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_100.iloc[cnt]\n",
    "\n",
    "print(\"-----------I have the schema generated as follows:---------\")\n",
    "temp_df = new_df[new_df['TESTFILE_PATH'] == sample['TESTFILE_PATH']]\n",
    "for idx, sql in enumerate(temp_df[temp_df['CASE_TYPE'] == 'Statement']['SQL']):\n",
    "    if idx >= 15:\n",
    "        break\n",
    "    print(sql + ';')\n",
    "print(\"-----------The SQL commands is:---------\")\n",
    "print(sample.SQL)\n",
    "print(\"-----------The expected result is:---------\")\n",
    "print(sample.EXPECTED_RESULT)\n",
    "print(\"-----------The actual result is:---------\")\n",
    "print(sample.ACTUAL_RESULT)\n",
    "print(\"-----------The error message is:---------\")\n",
    "print(sample.ERROR_MSG)\n",
    "print(sample.LOGS_INDEX)\n",
    "cnt += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['TESTFILE_PATH'])\n",
    "os.system(\"code \" + sample['TESTFILE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_100_reason = pd.read_csv(output_path)\n",
    "visible_reasons = sample_100_reason[[\n",
    "    'SQL', 'ERROR_REASON', 'ERROR_MSG', 'ACTUAL_RESULT', 'EXPECTED_RESULT',]]\n",
    "reasons_mapping = pd.read_csv('data/postgresql_suite_errors.csv')\n",
    "reasons_mapping = reasons_mapping[reasons_mapping['DBMS'] == dbms_name]\n",
    "# add columns to sample_100_reason according to reasons_mapping\n",
    "visible_reasons = pd.merge(visible_reasons, reasons_mapping,\n",
    "                           right_on='TAG', left_on='ERROR_REASON', how='inner')\n",
    "# visible_reasons.drop(columns=['TAG'], inplace=True)\n",
    "visible_reasons.to_csv(output_reason_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      " & DESCRIPTION \\\\\n",
      "SUPER_TAG &  \\\\\n",
      "Clause & 20 \\\\\n",
      "Command & 33 \\\\\n",
      "Function & 2 \\\\\n",
      "IType & 1 \\\\\n",
      "Operator & 3 \\\\\n",
      "Setting & 8 \\\\\n",
      "Type & 23 \\\\\n",
      "UFunction & 10 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reason_summary = visible_reasons[['SUPER_TAG',  'DESCRIPTION']].groupby(['SUPER_TAG']).count().style.to_latex()\n",
    "print(reason_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Command      17\n",
      "Type         10\n",
      "Clause        9\n",
      "UFunction     7\n",
      "Operator      6\n",
      "Function      2\n",
      "Setting       1\n",
      "IType         1\n",
      "Name: SUPER_TAG, dtype: int64\n",
      "SUPER_TAG\n",
      "Command      17\n",
      "Type         10\n",
      "Clause        9\n",
      "UFunction     7\n",
      "Operator      6\n",
      "Function      2\n",
      "IType         1\n",
      "Setting       1\n",
      "dtype: int64\n",
      "           ERROR_REASON  ERROR_REASON  ERROR_REASON\n",
      "SUPER_TAG                                          \n",
      "Clause               20            20            22\n",
      "Command              34            33            36\n",
      "Function              0             2             0\n",
      "IType                 0             1             0\n",
      "Operator             20             3            16\n",
      "Setting               0             8             2\n",
      "Type                 15            23            16\n",
      "UFunction            11            10             8\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  ERROR\\_REASON &  ERROR\\_REASON &  ERROR\\_REASON \\\\\n",
      "SUPER\\_TAG &               &               &               \\\\\n",
      "\\midrule\n",
      "Clause    &            20 &            20 &            22 \\\\\n",
      "Command   &            34 &            33 &            36 \\\\\n",
      "Function  &             0 &             2 &             0 \\\\\n",
      "IType     &             0 &             1 &             0 \\\\\n",
      "Operator  &            20 &             3 &            16 \\\\\n",
      "Setting   &             0 &             8 &             2 \\\\\n",
      "Type      &            15 &            23 &            16 \\\\\n",
      "UFunction &            11 &            10 &             8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1458502/1665073219.py:48: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(join_df.to_latex())\n"
     ]
    }
   ],
   "source": [
    "reasons = pd.read_csv(\"data/postgresql_suite_errors.csv\")\n",
    "\n",
    "sqlite_results = pd.read_csv(\"output/sqlite_postgresql_sample_100_reason.csv\")\n",
    "reason_df = sqlite_results[['SQL', 'EXPECTED_RESULT',\n",
    "                            'ACTUAL_RESULT', 'ERROR_REASON']]\n",
    "sqlite_reasons = reason_df['ERROR_REASON'].value_counts()\n",
    "\n",
    "\n",
    "duckdb_results = pd.read_csv(\n",
    "    \"output/duckdb_postgresql_sample_100_reason.csv\")\n",
    "reason_df = duckdb_results[['SQL', 'EXPECTED_RESULT',\n",
    "                                'ACTUAL_RESULT', 'ERROR_REASON']]\n",
    "duckdb_reasons = reason_df['ERROR_REASON'].value_counts()\n",
    "print(duckdb_reasons.sum())\n",
    "# mysql\n",
    "mysql_results = pd.read_csv(\"output/mysql_postgresql_sample_100_reason.csv\")\n",
    "reason_df = mysql_results[['SQL', 'EXPECTED_RESULT',\n",
    "                           'ACTUAL_RESULT', 'ERROR_REASON']]\n",
    "mysql_reasons = reason_df['ERROR_REASON'].value_counts()\n",
    "\n",
    "# print(sqlite_reasons)\n",
    "# print(duckdb_results)\n",
    "# outer join two dataframes\n",
    "\n",
    "join_df = pd.concat([sqlite_reasons, duckdb_reasons,\n",
    "                    mysql_reasons], axis=1, join='outer')\n",
    "# print(join_df)\n",
    "\n",
    "join_df.fillna(0, inplace=True)\n",
    "join_df = join_df.astype(int)\n",
    "\n",
    "# pure_reasons = reasons[['TAG', 'REASON']].drop_duplicates()\n",
    "pure_reasons = reasons[['TAG', 'SUPER_TAG']].drop_duplicates()\n",
    "print(pure_reasons['SUPER_TAG'].value_counts())\n",
    "# join the join_df and the reasons dataframe, drop duplicate rows\n",
    "join_df = join_df.join(pure_reasons.set_index('TAG'),  how='left')\n",
    "join_df.sort_values(by=['SUPER_TAG'], inplace=True)\n",
    "detail_df = join_df.copy()\n",
    "\n",
    "detail_df.drop(columns=['ERROR_REASON'], inplace=True)\n",
    "print(detail_df.value_counts())\n",
    "# sum the rows with the same SUPER_TAG\n",
    "join_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# unique_reasons = join_df['SUPER_TAG'].drop_duplicates()\n",
    "join_df = join_df.groupby('SUPER_TAG').sum()\n",
    "print(join_df)\n",
    "print(join_df.to_latex())\n",
    "# join_df.style.to_latex(\"output/error_reasons.tex\", )\n",
    "\n",
    "# unique_reasons = join_df['SUPER_TAG'].drop_duplicates()\n",
    "\n",
    "# iterate detail_df.value_counts()\n",
    "\n",
    "output_df = detail_df.value_counts()\n",
    "\n",
    "schema = \"\\\\newcommand{\\\\PostgreSQLCompatibilityIssue%s}{%s}\\n\"\n",
    "with open(\"output/Variables.tex\", \"a\") as f:\n",
    "\n",
    "    f.write(schema % ('SQL', output_df['Clause'] + output_df['Command']))\n",
    "    f.write(schema % ('Function', output_df['UFunction']))\n",
    "    f.write(schema % ('Type', output_df['Type']))\n",
    "    f.write(schema % ('Operator', output_df['Operator']))\n",
    "    f.write(schema % ('Configuration', output_df['Setting']))\n",
    "    f.write(schema % ('Semantic', output_df['Function'] +  output_df['IType']))\n",
    "    # f.write(schema % ('Misc', output_df['Misc']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
